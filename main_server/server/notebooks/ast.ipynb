{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd3e9b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a208d29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "code = \"\"\"\n",
    "import uuid\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Optional\n",
    "import pandas as pd\n",
    "from synesis_data_structures.time_series.df_dataclasses import TimeSeriesStructure, TimeSeriesAggregationStructure\n",
    "\n",
    "@dataclass\n",
    "class FunctionArgs:\n",
    "    window_size: int = 100\n",
    "    overlap: int = 0\n",
    "    target_columns: Optional[List[str]] = None\n",
    "\n",
    "@dataclass\n",
    "class OutputVariables:\n",
    "    number_of_windows: int\n",
    "\n",
    "@dataclass\n",
    "class FunctionInput:\n",
    "    function_args: FunctionArgs\n",
    "    input_time_series: TimeSeriesStructure\n",
    "\n",
    "@dataclass\n",
    "class FunctionOutput:\n",
    "    aggregated_means: TimeSeriesAggregationStructure\n",
    "    output_variables: OutputVariables\n",
    "\n",
    "def window_mean_aggregation(input: FunctionInput) -> FunctionOutput:\n",
    "    time_series_data = input.input_time_series.time_series_data\n",
    "    entity_metadata = input.input_time_series.entity_metadata\n",
    "    feature_info = input.input_time_series.feature_information\n",
    "    window_size = input.function_args.window_size\n",
    "    overlap = input.function_args.overlap\n",
    "    if input.function_args.target_columns is None:\n",
    "        target_columns = list(time_series_data.columns)\n",
    "    else:\n",
    "        target_columns = input.function_args.target_columns\n",
    "\n",
    "    # Prepare outputs\n",
    "    outputs_list = []\n",
    "    inputs_list = []\n",
    "    agg_metadata_list = []\n",
    "    number_of_windows = 0\n",
    "\n",
    "    for entity in time_series_data.index.get_level_values(0).unique():\n",
    "        entity_df = time_series_data.loc[entity].sort_index()\n",
    "        timestamps = entity_df.index\n",
    "        num_points = len(entity_df)\n",
    "        if overlap == 0:\n",
    "            step = window_size\n",
    "        else:\n",
    "            step = window_size - overlap\n",
    "        windows = []\n",
    "        for start_idx in range(0, num_points - window_size + 1, step):\n",
    "            end_idx = start_idx + window_size\n",
    "            windows.append((start_idx, end_idx))\n",
    "        number_of_windows += len(windows)\n",
    "        for start_idx, end_idx in windows:\n",
    "            agg_id = str(uuid.uuid4())\n",
    "            start_ts = timestamps[start_idx]\n",
    "            end_ts = timestamps[end_idx - 1]\n",
    "            # Compute means\n",
    "            mean_values = {}\n",
    "            for col in target_columns:\n",
    "                mean_val = entity_df.iloc[start_idx:end_idx][col].mean()\n",
    "                mean_values[f'mean_{col}'] = mean_val\n",
    "                # Add to inputs\n",
    "                inputs_list.append({\n",
    "                    'aggregation_id': agg_id,\n",
    "                    'time_series_id': entity,\n",
    "                    'input_feature_name': col,\n",
    "                    'start_timestamp': start_ts,\n",
    "                    'end_timestamp': end_ts\n",
    "                })\n",
    "            # Add to outputs\n",
    "            outputs_list.append({**mean_values, 'aggregation_id': agg_id})\n",
    "            # Add to agg metadata\n",
    "            agg_metadata_list.append({\n",
    "                'aggregation_id': agg_id,\n",
    "                'is_multi_series_computation': False,\n",
    "                'window_size': window_size\n",
    "            })\n",
    "\n",
    "    # Create dataframes\n",
    "    outputs_df = pd.DataFrame(outputs_list).set_index('aggregation_id')\n",
    "    inputs_df = pd.DataFrame(inputs_list)\n",
    "    agg_metadata_df = pd.DataFrame(agg_metadata_list).set_index('aggregation_id')\n",
    "\n",
    "    # Feature information for outputs\n",
    "    output_features = []\n",
    "    for col in target_columns:\n",
    "        input_feat = feature_info.loc[col]\n",
    "        output_feat = {\n",
    "            'name': f'mean_{col}',\n",
    "            'unit': input_feat['unit'],\n",
    "            'description': f'Mean value of {input_feat[\"description\"]}',\n",
    "            'type': 'numerical',\n",
    "            'subtype': 'continuous',\n",
    "            'scale': 'ratio',\n",
    "            'source': 'data',\n",
    "            'category_id': pd.NA\n",
    "        }\n",
    "        output_features.append(output_feat)\n",
    "    feature_info_outputs = pd.DataFrame(output_features).set_index('name')\n",
    "\n",
    "    # Create the structure\n",
    "    agg_structure = TimeSeriesAggregationStructure(\n",
    "        time_series_aggregation_outputs=outputs_df,\n",
    "        time_series_aggregation_inputs=inputs_df,\n",
    "        entity_metadata=agg_metadata_df,\n",
    "        feature_information=feature_info_outputs\n",
    "    )\n",
    "\n",
    "    output_vars = OutputVariables(number_of_windows=number_of_windows)\n",
    "\n",
    "    return FunctionOutput(\n",
    "        aggregated_means=agg_structure,\n",
    "        output_variables=output_vars\n",
    "    )\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c1a7066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'window_mean_aggregation'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descs=[]\n",
    "tree = ast.parse(code)\n",
    "for node in ast.walk(tree):\n",
    "    if isinstance(node, ast.FunctionDef):\n",
    "        descs.append(node.name)\n",
    "\"\\n\\n\".join(descs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6de98af7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['class FunctionArgs:\\n    window_size: int = 100\\n    overlap: int = 0\\n    target_columns: Optional[List[str]] = None',\n",
       " 'class OutputVariables:\\n    number_of_windows: int',\n",
       " 'class FunctionInput:\\n    function_args: FunctionArgs\\n    input_time_series: TimeSeriesStructure',\n",
       " 'class FunctionOutput:\\n    aggregated_means: TimeSeriesAggregationStructure\\n    output_variables: OutputVariables']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_dataclass_definition(source_code):\n",
    "    tree = ast.parse(source_code)\n",
    "    dataclass_definitions = []\n",
    "\n",
    "    for node in ast.walk(tree):\n",
    "        if isinstance(node, ast.ClassDef):\n",
    "            for decorator in node.decorator_list:\n",
    "                if isinstance(decorator, ast.Name) and decorator.id == \"dataclass\":\n",
    "                    source_segment = ast.get_source_segment(source_code, node)\n",
    "                    if source_segment:\n",
    "                        dataclass_definitions.append(source_segment)\n",
    "                elif isinstance(decorator, ast.Call) and isinstance(decorator.func, ast.Name) and decorator.func.id == \"dataclass\":\n",
    "                    source_segment = ast.get_source_segment(source_code, node)\n",
    "                    if source_segment:\n",
    "                        dataclass_definitions.append(source_segment)\n",
    "\n",
    "    return dataclass_definitions\n",
    "\n",
    "extract_dataclass_definition(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44f670ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Function: window_mean_aggregation\\n\\n  Parameters:\\n    - input: FunctionInput\\n\\nReturn Type: FunctionOutput']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_function_definitions(source_code):\n",
    "    tree = ast.parse(source_code)\n",
    "    function_summaries = []\n",
    "\n",
    "    for node in ast.walk(tree):\n",
    "        if isinstance(node, ast.FunctionDef):\n",
    "            func_name = node.name\n",
    "\n",
    "            params = []\n",
    "            for arg in node.args.args:\n",
    "                param_name = arg.arg\n",
    "                param_type = ast.unparse(\n",
    "                    arg.annotation) if arg.annotation else \"Any\"\n",
    "                params.append(f\"{param_name}: {param_type}\")\n",
    "            for kwarg in node.args.kwonlyargs:\n",
    "                param_name = kwarg.arg\n",
    "                param_type = ast.unparse(\n",
    "                    kwarg.annotation) if kwarg.annotation else \"Any\"\n",
    "                params.append(f\"{param_name}: {param_type} (keyword-only)\")\n",
    "\n",
    "            return_type = ast.unparse(node.returns) if node.returns else \"Any\"\n",
    "\n",
    "            summary = f\"Function: {func_name}\\n\\n\"\n",
    "            summary += \"  Parameters:\\n\"\n",
    "            if params:\n",
    "                for param in params:\n",
    "                    summary += f\"    - {param}\\n\"\n",
    "            else:\n",
    "                summary += \"    - None\\n\"\n",
    "            summary += f\"\\nReturn Type: {return_type}\"\n",
    "\n",
    "            function_summaries.append(summary)\n",
    "\n",
    "    return function_summaries\n",
    "\n",
    "extract_function_definitions(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a829bf47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, List\n",
    "\n",
    "def get_type_annotation(node) -> str:\n",
    "    \"\"\"Helper to convert type annotation to string.\"\"\"\n",
    "    if isinstance(node, ast.Name):\n",
    "        return node.id\n",
    "    elif isinstance(node, ast.Subscript):\n",
    "        return f\"{get_type_annotation(node.value)}[{get_type_annotation(node.slice)}]\"\n",
    "    elif isinstance(node, ast.Constant):\n",
    "        return str(node.value)\n",
    "    elif isinstance(node, ast.Attribute):\n",
    "        return f\"{get_type_annotation(node.value)}.{node.attr}\"\n",
    "    elif isinstance(node, (ast.Tuple, ast.List)):\n",
    "        elements = [get_type_annotation(el) for el in node.elts]\n",
    "        return f\"Tuple[{', '.join(elements)}]\" if isinstance(node, ast.Tuple) else f\"List[{', '.join(elements)}]\"\n",
    "    return \"Any\"\n",
    "\n",
    "\n",
    "def is_dataclass(node: ast.ClassDef) -> bool:\n",
    "    \"\"\"Check if a class is a dataclass.\"\"\"\n",
    "    for decorator in node.decorator_list:\n",
    "        if isinstance(decorator, ast.Name) and decorator.id == \"dataclass\":\n",
    "            return True\n",
    "        elif isinstance(decorator, ast.Call) and isinstance(decorator.func, ast.Name) and decorator.func.id == \"dataclass\":\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def extract_method_info(node: ast.FunctionDef) -> Tuple[str, List[Tuple[str, str]], str]:\n",
    "    \"\"\"Extract method name, parameters, and return type.\"\"\"\n",
    "    params = []\n",
    "    for arg in node.args.args:\n",
    "        param_name = arg.arg\n",
    "        param_type = get_type_annotation(\n",
    "            arg.annotation) if arg.annotation else \"Any\"\n",
    "        params.append((param_name, param_type))\n",
    "\n",
    "    return_type = get_type_annotation(node.returns) if node.returns else \"None\"\n",
    "    return node.name, params, return_type\n",
    "\n",
    "\n",
    "def extract_class_definitions(code: str) -> List[dict]:\n",
    "    tree = ast.parse(code)\n",
    "    class_info_list = []\n",
    "\n",
    "    for node in ast.walk(tree):\n",
    "        if isinstance(node, ast.ClassDef) and not is_dataclass(node):\n",
    "            class_info = {\n",
    "                \"name\": node.name,\n",
    "                \"init\": None,\n",
    "                \"methods\": []\n",
    "            }\n",
    "\n",
    "            for item in node.body:\n",
    "                if isinstance(item, ast.FunctionDef):\n",
    "                    method_name, params, return_type = extract_method_info(\n",
    "                        item)\n",
    "                    method_info = {\n",
    "                        \"name\": method_name,\n",
    "                        \"parameters\": params,\n",
    "                        \"return_type\": return_type\n",
    "                    }\n",
    "\n",
    "                    if method_name == \"__init__\":\n",
    "                        class_info[\"init\"] = method_info\n",
    "                    else:\n",
    "                        class_info[\"methods\"].append(method_info)\n",
    "\n",
    "            class_info_list.append(class_info)\n",
    "\n",
    "    output = []\n",
    "    for cls in class_info_list:\n",
    "        output.append(f\"Class: {cls['name']}\")\n",
    "\n",
    "        if cls['init']:\n",
    "            init = cls['init']\n",
    "            params = \", \".join(f\"{name}: {type_}\" for name,\n",
    "                               type_ in init['parameters'])\n",
    "            output.append(f\"  __init__({params}) -> {init['return_type']}\")\n",
    "\n",
    "        if cls['methods']:\n",
    "            output.append(\"  Methods:\")\n",
    "            for method in cls['methods']:\n",
    "                params = \", \".join(\n",
    "                    f\"{name}: {type_}\" for name, type_ in method['parameters'])\n",
    "                output.append(\n",
    "                    f\"    {method['name']}({params}) -> {method['return_type']}\")\n",
    "\n",
    "        output.append(\"\")  # Empty line between classes\n",
    "\n",
    "    return \"\\n\".join(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "186bd692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: RegularClass\n",
      "  __init__(self: Any, name: str, value: int) -> None\n",
      "  Methods:\n",
      "    process(self: Any, input_list: List[int]) -> str\n",
      "    get_value(self: Any) -> int\n",
      "\n",
      "Class: AnotherClass\n",
      "  Methods:\n",
      "    compute(self: Any, x: float, y: float) -> float\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_code = \"\"\"\n",
    "from dataclasses import dataclass\n",
    "from typing import List\n",
    "\n",
    "@dataclass\n",
    "class DataClassExample:\n",
    "    x: int\n",
    "    y: str\n",
    "\n",
    "class RegularClass:\n",
    "    def __init__(self, name: str, value: int) -> None:\n",
    "        self.name = name\n",
    "        self.value = value\n",
    "    \n",
    "    def process(self, input_list: List[int]) -> str:\n",
    "        return f\"Processed {len(input_list)} items\"\n",
    "    \n",
    "    def get_value(self) -> int:\n",
    "        return self.value\n",
    "\n",
    "class AnotherClass:\n",
    "    def compute(self, x: float, y: float) -> float:\n",
    "        return x + y\n",
    "\"\"\"\n",
    "\n",
    "print(extract_class_definitions(sample_code))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kvasir",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
