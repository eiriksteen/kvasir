"""Upgrade data source models

Revision ID: 7053500a7d92
Revises: 703d3dff0b78
Create Date: 2025-09-05 17:04:57.515200

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision: str = '7053500a7d92'
down_revision: Union[str, None] = '703d3dff0b78'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('data_source_analysis',
                    sa.Column('id', sa.UUID(), nullable=False),
                    sa.Column('data_source_id', sa.UUID(), nullable=False),
                    sa.Column('content_description',
                              sa.String(), nullable=False),
                    sa.Column('quality_description',
                              sa.String(), nullable=False),
                    sa.Column('eda_summary', sa.String(), nullable=False),
                    sa.Column('cautions', sa.String(), nullable=False),
                    sa.Column('created_at', sa.DateTime(
                        timezone=True), nullable=False),
                    sa.Column('updated_at', sa.DateTime(
                        timezone=True), nullable=False),
                    sa.ForeignKeyConstraint(['data_source_id'], [
                        'data_sources.data_source.id'], ),
                    sa.ForeignKeyConstraint(
                        ['id'], ['data_sources.data_source.id'], ),
                    sa.PrimaryKeyConstraint('id'),
                    schema='data_sources'
                    )
    op.execute('DROP TABLE IF EXISTS data_sources.data_source_group CASCADE')
    op.execute('DROP TABLE IF EXISTS data_sources.subgroup CASCADE')
    op.execute('DROP TABLE IF EXISTS data_sources.file_data_source CASCADE')
    op.execute('DROP TABLE IF EXISTS data_sources.data_source_in_group CASCADE')
    op.add_column('data_source', sa.Column('updated_at', sa.DateTime(
        timezone=True), nullable=False), schema='data_sources')
    op.drop_column('data_source', 'content_preview', schema='data_sources')
    op.drop_column('data_source', 'quality_description', schema='data_sources')
    op.drop_column('data_source', 'description', schema='data_sources')
    op.add_column('tabular_file_data_source', sa.Column(
        'file_name', sa.String(), nullable=False), schema='data_sources')
    op.add_column('tabular_file_data_source', sa.Column(
        'file_path', sa.String(), nullable=False), schema='data_sources')
    op.add_column('tabular_file_data_source', sa.Column(
        'file_type', sa.String(), nullable=False), schema='data_sources')
    op.add_column('tabular_file_data_source', sa.Column(
        'file_size_bytes', sa.BigInteger(), nullable=False), schema='data_sources')
    op.add_column('tabular_file_data_source', sa.Column(
        'content_preview', sa.String(), nullable=True), schema='data_sources')
    op.execute('ALTER TABLE data_sources.tabular_file_data_source DROP CONSTRAINT IF EXISTS tabular_file_data_source_id_fkey')
    op.create_foreign_key(None, 'tabular_file_data_source', 'data_source', ['id'], [
                          'id'], source_schema='data_sources', referent_schema='data_sources')
    op.alter_column('run', 'conversation_id',
                    existing_type=sa.UUID(),
                    nullable=True,
                    schema='runs')
    # ### end Alembic commands ###


def downgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.alter_column('run', 'conversation_id',
                    existing_type=sa.UUID(),
                    nullable=False,
                    schema='runs')
    op.execute('ALTER TABLE data_sources.tabular_file_data_source DROP CONSTRAINT IF EXISTS tabular_file_data_source_id_fkey')
    op.create_foreign_key(op.f('tabular_file_data_source_id_fkey'), 'tabular_file_data_source', 'file_data_source', [
                          'id'], ['id'], source_schema='data_sources', referent_schema='data_sources')
    op.drop_column('tabular_file_data_source',
                   'content_preview', schema='data_sources')
    op.drop_column('tabular_file_data_source',
                   'file_size_bytes', schema='data_sources')
    op.drop_column('tabular_file_data_source',
                   'file_type', schema='data_sources')
    op.drop_column('tabular_file_data_source',
                   'file_path', schema='data_sources')
    op.drop_column('tabular_file_data_source',
                   'file_name', schema='data_sources')
    op.add_column('data_source', sa.Column('description', sa.VARCHAR(
    ), autoincrement=False, nullable=True), schema='data_sources')
    op.add_column('data_source', sa.Column('quality_description', sa.VARCHAR(
    ), autoincrement=False, nullable=True), schema='data_sources')
    op.add_column('data_source', sa.Column('content_preview', sa.VARCHAR(
    ), autoincrement=False, nullable=True), schema='data_sources')
    op.drop_column('data_source', 'updated_at', schema='data_sources')
    op.create_table('data_source_in_group',
                    sa.Column('group_id', sa.UUID(),
                              autoincrement=False, nullable=False),
                    sa.Column('data_source_id', sa.UUID(),
                              autoincrement=False, nullable=False),
                    sa.Column('created_at', postgresql.TIMESTAMP(
                        timezone=True), autoincrement=False, nullable=False),
                    sa.Column('updated_at', postgresql.TIMESTAMP(
                        timezone=True), autoincrement=False, nullable=False),
                    sa.ForeignKeyConstraint(['data_source_id'], ['data_sources.data_source.id'], name=op.f(
                        'data_source_in_group_data_source_id_fkey')),
                    sa.ForeignKeyConstraint(['group_id'], ['data_sources.data_source_group.id'], name=op.f(
                        'data_source_in_group_group_id_fkey')),
                    sa.PrimaryKeyConstraint(
                        'group_id', name=op.f('data_source_in_group_pkey')),
                    schema='data_sources'
                    )
    op.create_table('file_data_source',
                    sa.Column('id', sa.UUID(),
                              autoincrement=False, nullable=False),
                    sa.Column('file_name', sa.VARCHAR(),
                              autoincrement=False, nullable=False),
                    sa.Column('file_path', sa.VARCHAR(),
                              autoincrement=False, nullable=False),
                    sa.Column('file_type', sa.VARCHAR(),
                              autoincrement=False, nullable=False),
                    sa.Column('file_size_bytes', sa.BIGINT(),
                              autoincrement=False, nullable=False),
                    sa.Column('created_at', postgresql.TIMESTAMP(
                        timezone=True), autoincrement=False, nullable=False),
                    sa.Column('updated_at', postgresql.TIMESTAMP(
                        timezone=True), autoincrement=False, nullable=False),
                    sa.ForeignKeyConstraint(['id'], ['data_sources.data_source.id'], name=op.f(
                        'file_data_source_id_fkey')),
                    sa.PrimaryKeyConstraint(
                        'id', name=op.f('file_data_source_pkey')),
                    schema='data_sources'
                    )
    op.create_table('subgroup',
                    sa.Column('id', sa.UUID(),
                              autoincrement=False, nullable=False),
                    sa.Column('parent_group_id', sa.UUID(),
                              autoincrement=False, nullable=False),
                    sa.Column('child_group_id', sa.UUID(),
                              autoincrement=False, nullable=False),
                    sa.Column('created_at', postgresql.TIMESTAMP(
                        timezone=True), autoincrement=False, nullable=False),
                    sa.ForeignKeyConstraint(['child_group_id'], [
                        'data_sources.data_source_group.id'], name=op.f('subgroup_child_group_id_fkey')),
                    sa.ForeignKeyConstraint(['parent_group_id'], [
                        'data_sources.data_source_group.id'], name=op.f('subgroup_parent_group_id_fkey')),
                    sa.PrimaryKeyConstraint('id', name=op.f('subgroup_pkey')),
                    schema='data_sources'
                    )
    op.create_table('data_source_group',
                    sa.Column('id', sa.UUID(),
                              autoincrement=False, nullable=False),
                    sa.Column('name', sa.VARCHAR(),
                              autoincrement=False, nullable=False),
                    sa.Column('description', sa.VARCHAR(),
                              autoincrement=False, nullable=True),
                    sa.Column('created_at', postgresql.TIMESTAMP(
                        timezone=True), autoincrement=False, nullable=False),
                    sa.Column('updated_at', postgresql.TIMESTAMP(
                        timezone=True), autoincrement=False, nullable=False),
                    sa.PrimaryKeyConstraint(
                        'id', name=op.f('data_source_group_pkey')),
                    schema='data_sources'
                    )
    op.execute('DROP TABLE IF EXISTS data_sources.data_source_analysis CASCADE')
    # ### end Alembic commands ###
