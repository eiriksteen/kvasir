"""Add run entity inputs / outputs models

Revision ID: 9013649406f4
Revises: 730504bc67fa
Create Date: 2025-10-10 23:36:11.937381

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision: str = '9013649406f4'
down_revision: Union[str, None] = '730504bc67fa'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('data_source_from_run',
    sa.Column('run_id', sa.UUID(), nullable=False),
    sa.Column('data_source_id', sa.UUID(), nullable=False),
    sa.Column('created_at', sa.DateTime(timezone=True), nullable=False),
    sa.ForeignKeyConstraint(['data_source_id'], ['data_sources.data_source.id'], ),
    sa.ForeignKeyConstraint(['run_id'], ['runs.run.id'], ),
    sa.PrimaryKeyConstraint('run_id', 'data_source_id'),
    schema='runs'
    )
    op.create_table('dataset_from_run',
    sa.Column('run_id', sa.UUID(), nullable=False),
    sa.Column('dataset_id', sa.UUID(), nullable=False),
    sa.Column('created_at', sa.DateTime(timezone=True), nullable=False),
    sa.ForeignKeyConstraint(['dataset_id'], ['data_objects.dataset.id'], ),
    sa.ForeignKeyConstraint(['run_id'], ['runs.run.id'], ),
    sa.PrimaryKeyConstraint('run_id', 'dataset_id'),
    schema='runs'
    )
    op.create_table('model_entity_from_run',
    sa.Column('run_id', sa.UUID(), nullable=False),
    sa.Column('model_entity_id', sa.UUID(), nullable=False),
    sa.Column('created_at', sa.DateTime(timezone=True), nullable=False),
    sa.ForeignKeyConstraint(['model_entity_id'], ['model.model_entity.id'], ),
    sa.ForeignKeyConstraint(['run_id'], ['runs.run.id'], ),
    sa.PrimaryKeyConstraint('run_id', 'model_entity_id'),
    schema='runs'
    )
    op.create_table('pipeline_from_run',
    sa.Column('run_id', sa.UUID(), nullable=False),
    sa.Column('pipeline_id', sa.UUID(), nullable=False),
    sa.Column('created_at', sa.DateTime(timezone=True), nullable=False),
    sa.ForeignKeyConstraint(['pipeline_id'], ['pipeline.pipeline.id'], ),
    sa.ForeignKeyConstraint(['run_id'], ['runs.run.id'], ),
    sa.PrimaryKeyConstraint('run_id', 'pipeline_id'),
    schema='runs'
    )
    op.drop_table('data_integration_run_input', schema='runs')
    op.drop_table('data_integration_run_result', schema='runs')
    # ### end Alembic commands ###


def downgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('data_integration_run_result',
    sa.Column('run_id', sa.UUID(), autoincrement=False, nullable=False),
    sa.Column('dataset_id', sa.UUID(), autoincrement=False, nullable=False),
    sa.Column('code_explanation', sa.VARCHAR(), autoincrement=False, nullable=False),
    sa.Column('python_code_path', sa.VARCHAR(), autoincrement=False, nullable=False),
    sa.Column('created_at', postgresql.TIMESTAMP(timezone=True), autoincrement=False, nullable=False),
    sa.Column('updated_at', postgresql.TIMESTAMP(timezone=True), autoincrement=False, nullable=False),
    sa.ForeignKeyConstraint(['dataset_id'], ['data_objects.dataset.id'], name=op.f('data_integration_run_result_dataset_id_fkey')),
    sa.ForeignKeyConstraint(['run_id'], ['runs.run.id'], name=op.f('data_integration_run_result_run_id_fkey')),
    sa.PrimaryKeyConstraint('run_id', name=op.f('data_integration_run_result_pkey')),
    schema='runs'
    )
    op.create_table('data_integration_run_input',
    sa.Column('run_id', sa.UUID(), autoincrement=False, nullable=False),
    sa.Column('target_dataset_description', sa.VARCHAR(), autoincrement=False, nullable=False),
    sa.Column('created_at', postgresql.TIMESTAMP(timezone=True), autoincrement=False, nullable=False),
    sa.Column('updated_at', postgresql.TIMESTAMP(timezone=True), autoincrement=False, nullable=False),
    sa.ForeignKeyConstraint(['run_id'], ['runs.run.id'], name=op.f('data_integration_run_input_run_id_fkey')),
    sa.PrimaryKeyConstraint('run_id', name=op.f('data_integration_run_input_pkey')),
    schema='runs'
    )
    op.drop_table('pipeline_from_run', schema='runs')
    op.drop_table('model_entity_from_run', schema='runs')
    op.drop_table('dataset_from_run', schema='runs')
    op.drop_table('data_source_from_run', schema='runs')
    # ### end Alembic commands ###
