"""updates from merge

Revision ID: 1bd9c7146ba7
Revises: e048eb9e6b84
Create Date: 2025-05-18 18:57:15.958746

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision: str = '1bd9c7146ba7'
down_revision: Union[str, None] = 'e048eb9e6b84'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('integration_jobs_directory_inputs',
    sa.Column('job_id', sa.UUID(), nullable=False),
    sa.Column('data_description', sa.String(), nullable=False),
    sa.Column('data_directory', sa.String(), nullable=False),
    sa.ForeignKeyConstraint(['job_id'], ['jobs.jobs.id'], ),
    sa.PrimaryKeyConstraint('job_id'),
    schema='integration'
    )
    op.create_table('integration_message',
    sa.Column('id', sa.UUID(), nullable=False),
    sa.Column('job_id', sa.UUID(), nullable=True),
    sa.Column('content', sa.String(), nullable=False),
    sa.Column('type', sa.String(), nullable=False),
    sa.Column('role', sa.String(), nullable=False),
    sa.Column('created_at', sa.DateTime(timezone=True), nullable=False),
    sa.ForeignKeyConstraint(['job_id'], ['jobs.jobs.id'], ),
    sa.PrimaryKeyConstraint('id'),
    schema='integration'
    )
    op.create_table('integration_pydantic_message',
    sa.Column('id', sa.UUID(), nullable=False),
    sa.Column('job_id', sa.UUID(), nullable=True),
    sa.Column('message_list', postgresql.BYTEA(), nullable=False),
    sa.Column('created_at', sa.DateTime(timezone=True), nullable=False),
    sa.ForeignKeyConstraint(['job_id'], ['jobs.jobs.id'], ),
    sa.PrimaryKeyConstraint('id'),
    schema='integration'
    )
    op.create_table('dataset_metadata',
    sa.Column('dataset_id', sa.UUID(), nullable=False),
    sa.Column('column_names', postgresql.ARRAY(sa.String()), nullable=False),
    sa.Column('column_types', postgresql.ARRAY(sa.String()), nullable=False),
    sa.Column('num_columns', sa.Integer(), nullable=False),
    sa.ForeignKeyConstraint(['dataset_id'], ['ontology.dataset.id'], ),
    sa.PrimaryKeyConstraint('dataset_id'),
    schema='ontology'
    )
    op.alter_column('chat_message', 'created_at',
               existing_type=postgresql.TIMESTAMP(),
               type_=sa.DateTime(timezone=True),
               existing_nullable=False,
               schema='chat')
    op.alter_column('context', 'created_at',
               existing_type=postgresql.TIMESTAMP(),
               type_=sa.DateTime(timezone=True),
               existing_nullable=False,
               schema='chat')
    op.alter_column('pydantic_message', 'created_at',
               existing_type=postgresql.TIMESTAMP(),
               type_=sa.DateTime(timezone=True),
               existing_nullable=False,
               schema='chat')
    op.add_column('jobs', sa.Column('job_name', sa.String(), nullable=True), schema='jobs')
    op.alter_column('jobs', 'started_at',
               existing_type=postgresql.TIMESTAMP(),
               type_=sa.DateTime(timezone=True),
               existing_nullable=False,
               schema='jobs')
    op.alter_column('jobs', 'completed_at',
               existing_type=postgresql.TIMESTAMP(),
               type_=sa.DateTime(timezone=True),
               existing_nullable=True,
               schema='jobs')
    op.drop_constraint('jobs_api_key_id_fkey', 'jobs', schema='jobs', type_='foreignkey')
    op.drop_column('jobs', 'api_key_id', schema='jobs')
    op.alter_column('dataset', 'created_at',
               existing_type=postgresql.TIMESTAMP(),
               type_=sa.DateTime(timezone=True),
               existing_nullable=False,
               schema='ontology')
    op.alter_column('dataset', 'updated_at',
               existing_type=postgresql.TIMESTAMP(),
               type_=sa.DateTime(timezone=True),
               existing_nullable=False,
               schema='ontology')
    op.alter_column('time_series', 'start_timestamp',
               existing_type=postgresql.TIMESTAMP(),
               type_=sa.DateTime(timezone=True),
               existing_nullable=False,
               schema='ontology')
    op.alter_column('time_series', 'end_timestamp',
               existing_type=postgresql.TIMESTAMP(),
               type_=sa.DateTime(timezone=True),
               existing_nullable=False,
               schema='ontology')
    # ### end Alembic commands ###


def downgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.alter_column('time_series', 'end_timestamp',
               existing_type=sa.DateTime(timezone=True),
               type_=postgresql.TIMESTAMP(),
               existing_nullable=False,
               schema='ontology')
    op.alter_column('time_series', 'start_timestamp',
               existing_type=sa.DateTime(timezone=True),
               type_=postgresql.TIMESTAMP(),
               existing_nullable=False,
               schema='ontology')
    op.alter_column('dataset', 'updated_at',
               existing_type=sa.DateTime(timezone=True),
               type_=postgresql.TIMESTAMP(),
               existing_nullable=False,
               schema='ontology')
    op.alter_column('dataset', 'created_at',
               existing_type=sa.DateTime(timezone=True),
               type_=postgresql.TIMESTAMP(),
               existing_nullable=False,
               schema='ontology')
    op.add_column('jobs', sa.Column('api_key_id', sa.UUID(), autoincrement=False, nullable=False), schema='jobs')
    op.create_foreign_key('jobs_api_key_id_fkey', 'jobs', 'user_api_keys', ['api_key_id'], ['id'], source_schema='jobs', referent_schema='auth')
    op.alter_column('jobs', 'completed_at',
               existing_type=sa.DateTime(timezone=True),
               type_=postgresql.TIMESTAMP(),
               existing_nullable=True,
               schema='jobs')
    op.alter_column('jobs', 'started_at',
               existing_type=sa.DateTime(timezone=True),
               type_=postgresql.TIMESTAMP(),
               existing_nullable=False,
               schema='jobs')
    op.drop_column('jobs', 'job_name', schema='jobs')
    op.alter_column('pydantic_message', 'created_at',
               existing_type=sa.DateTime(timezone=True),
               type_=postgresql.TIMESTAMP(),
               existing_nullable=False,
               schema='chat')
    op.alter_column('context', 'created_at',
               existing_type=sa.DateTime(timezone=True),
               type_=postgresql.TIMESTAMP(),
               existing_nullable=False,
               schema='chat')
    op.alter_column('chat_message', 'created_at',
               existing_type=sa.DateTime(timezone=True),
               type_=postgresql.TIMESTAMP(),
               existing_nullable=False,
               schema='chat')
    op.drop_table('dataset_metadata', schema='ontology')
    op.drop_table('integration_pydantic_message', schema='integration')
    op.drop_table('integration_message', schema='integration')
    op.drop_table('integration_jobs_directory_inputs', schema='integration')
    # ### end Alembic commands ###
