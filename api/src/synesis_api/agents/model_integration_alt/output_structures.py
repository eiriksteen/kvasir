from typing import List

# TIME_SERIES_SUPPORTED_TASKS = ["classification", "forecasting", "segmentation"]
TIME_SERIES_SUPPORTED_TASKS = ["forecasting"]  # only forecasting for now

SUPPORTED_MODALITIES = ["time_series"]

TIME_SERIES_FORECASTING_OUTPUT_STRUCTURE = f"""
When generating the forecast, take the most recent data as input to produce a forecast for the future. 
In case the input has multiple entities, we want a forecast for each entity. 
If the model allows for it, use batching to achieve this, the output should have the shape (num_entities, output_features, pred_len). 
Unless otherwise specified, forecast all the input features in the dataset, and use the default pred_len from the repository. 
Use the last seq_len data points as input to produce a forecast for the future, using the default seq_len from the repository.
Finally, output a list of objects with the following structure:

{{
    "time_series_id": "str",
    "start_timestamp": "datetime",
    "end_timestamp": "datetime",
    "forecast_horizon": "int",
    "forecast_values": "list[list[float]]",
    "forecast_mu": "list[list[float]] | None",
    "forecast_lower": "list[list[float]] | None",
    "forecast_upper": "list[list[float]] | None",
}}

Where the time_series_id is the id of the entity, 
the start_timestamp is the start timestamp of the forecast, 
the end_timestamp is the end timestamp of the forecast, 
the forecast_horizon is the forecast horizon, 
the forecast_values is the forecast values, 
the forecast_mu is the forecast mean (optional, based on the model), 
the forecast_lower is the forecast lower bound (optional, based on the model), 
the forecast_upper is the forecast upper bound (optional, based on the model).
"""

TIME_SERIES_CLASSIFICATION_OUTPUT_STRUCTURE = f"""
We must go through the whole input data to classify the entire input. 
That means, for each entity, slice the time_series into subseries of length seq_len (use the default seq_len from the repository).
Then, produce a classification for each subseries.
Finally, output a list of objects with the following structure:

{{
    "classification_id": "str",
    "time_series_id": "str",
    "start_timestamp": "datetime",
    "end_timestamp": "datetime",
    "id_to_label": "dict[int, str]",
    "class_label": "int",
    "class_probability": "float | None"
}}

Where the classification_id is a unique UUIDv4 for each classification, generated by you
the time_series_id is the id of the entity, 
the start_timestamp is the start timestamp of the subseries, 
the end_timestamp is the end timestamp of the subseries, 
the class_label is the class label of the subseries, 
and the class_probability is the probability of the class label (optional, based on the model).
"""

TIME_SERIES_SEGMENTATION_OUTPUT_STRUCTURE = f"""
We must go through the whole input data to segment the entire input. 
That means, for each entity, slice the time_series into subseries of length seq_len (use the default seq_len from the repository).
Then, produce a segmentation for each subseries.
Finally, output a list of objects with the following structure:

{{
    "time_series_id": "str",
    "start_timestamp": "datetime",
    "end_timestamp": "datetime",
    "id_to_label": "dict[int, str]",
    "segmented_output": "list[list[int]]"
}}

Where the time_series_id is the id of the entity, 
the start_timestamp is the start timestamp of the subseries, 
the end_timestamp is the end timestamp of the subseries, 
the id_to_label is a dictionary that maps the integer labels to the string labels, 
and the segmented_output is a list of lists of integers, where for each feature, the list of integers is a segmentation of the subseries.
"""

TIME_SERIES_FORECASTING_VALIDATION = '''
from datetime import datetime
from typing import Dict, Any, List

def validate_inference_output(outputs: List[Dict[str, Any]]) -> None:
    """Validate the structure of time series forecasting outputs.
    
    Args:
        outputs: List of output dictionaries to validate
        
    Raises:
        ValueError: If any output structure is invalid, with a descriptive message.
    """
    if not isinstance(outputs, list):
        raise ValueError("Output must be a list of dictionaries")
    
    if not outputs:
        raise ValueError("Output list cannot be empty")
        
    required_fields = {
        "time_series_id": str,
        "start_timestamp": datetime,
        "end_timestamp": datetime,
        "forecast_horizon": int,
        "forecast_values": list
    }
    
    for output in outputs:
        # Check all required fields exist and have correct types
        for field, expected_type in required_fields.items():
            if field not in output:
                raise ValueError(f"Missing required field: {field}")
            if not isinstance(output[field], expected_type):
                raise ValueError(f"Field {field} must be of type {expected_type.__name__}, got {type(output[field]).__name__}")
        
        # Validate forecast_values structure
        if not all(isinstance(x, list) for x in output["forecast_values"]):
            raise ValueError("forecast_values must be a list of lists")
        if not all(all(isinstance(x, (int, float)) for x in inner_list) 
                  for inner_list in output["forecast_values"]):
            raise ValueError("All values in forecast_values must be numbers (int or float)")
        
        # Validate optional fields if they exist
        optional_fields = {
            "forecast_mu": list,
            "forecast_lower": list,
            "forecast_upper": list
        }
        
        for field, expected_type in optional_fields.items():
            if field in output:
                if not isinstance(output[field], expected_type):
                    raise ValueError(f"Optional field {field} must be of type {expected_type.__name__}, got {type(output[field]).__name__}")
                if not all(isinstance(x, list) for x in output[field]):
                    raise ValueError(f"{field} must be a list of lists")
                if not all(all(isinstance(x, (int, float)) for x in inner_list) 
                          for inner_list in output[field]):
                    raise ValueError(f"All values in {field} must be numbers (int or float)")
'''

TIME_SERIES_CLASSIFICATION_VALIDATION = '''
from datetime import datetime
import uuid
from typing import Dict, Any, List

def validate_inference_output(outputs: List[Dict[str, Any]]) -> None:
    """Validate the structure of time series classification outputs.
    
    Args:
        outputs: List of output dictionaries to validate
        
    Raises:
        ValueError: If any output structure is invalid, with a descriptive message.
    """
    if not isinstance(outputs, list):
        raise ValueError("Output must be a list of dictionaries")
    
    if not outputs:
        raise ValueError("Output list cannot be empty")
        
    required_fields = {
        "classification_id": str,
        "time_series_id": str,
        "start_timestamp": datetime,
        "end_timestamp": datetime,
        "id_to_label": dict,
        "class_label": int
    }
    
    for output in outputs:
        # Check all required fields exist and have correct types
        for field, expected_type in required_fields.items():
            if field not in output:
                raise ValueError(f"Missing required field: {field}")
            if not isinstance(output[field], expected_type):
                raise ValueError(f"Field {field} must be of type {expected_type.__name__}, got {type(output[field]).__name__}")
        
        # Validate classification_id is a valid UUID
        try:
            uuid.UUID(output["classification_id"])
        except ValueError:
            raise ValueError("classification_id must be a valid UUID")
        
        # Validate id_to_label structure
        if not all(isinstance(k, int) and isinstance(v, str) 
                  for k, v in output["id_to_label"].items()):
            raise ValueError("id_to_label must be a dictionary mapping integers to strings")
        
        # Validate optional class_probability
        if "class_probability" in output:
            if not isinstance(output["class_probability"], (int, float)):
                raise ValueError("class_probability must be a number (int or float)")
            if not 0 <= output["class_probability"] <= 1:
                raise ValueError("class_probability must be between 0 and 1")
'''

TIME_SERIES_SEGMENTATION_VALIDATION = '''
from datetime import datetime
from typing import Dict, Any, List

def validate_inference_output(outputs: List[Dict[str, Any]]) -> None:
    """Validate the structure of time series segmentation outputs.
    
    Args:
        outputs: List of output dictionaries to validate
        
    Raises:
        ValueError: If any output structure is invalid, with a descriptive message.
    """
    if not isinstance(outputs, list):
        raise ValueError("Output must be a list of dictionaries")
    
    if not outputs:
        raise ValueError("Output list cannot be empty")
        
    required_fields = {
        "time_series_id": str,
        "start_timestamp": datetime,
        "end_timestamp": datetime,
        "id_to_label": dict,
        "segmented_output": list
    }
    
    for output in outputs:
        # Check all required fields exist and have correct types
        for field, expected_type in required_fields.items():
            if field not in output:
                raise ValueError(f"Missing required field: {field}")
            if not isinstance(output[field], expected_type):
                raise ValueError(f"Field {field} must be of type {expected_type.__name__}, got {type(output[field]).__name__}")
        
        # Validate id_to_label structure
        if not all(isinstance(k, int) and isinstance(v, str) 
                  for k, v in output["id_to_label"].items()):
            raise ValueError("id_to_label must be a dictionary mapping integers to strings")
        
        # Validate segmented_output structure
        if not all(isinstance(x, list) for x in output["segmented_output"]):
            raise ValueError("segmented_output must be a list of lists")
        if not all(all(isinstance(x, int) for x in inner_list) 
                  for inner_list in output["segmented_output"]):
            raise ValueError("All values in segmented_output must be integers")
        
        # Validate that all integers in segmented_output are valid keys in id_to_label
        valid_labels = set(output["id_to_label"].keys())
        if not all(all(x in valid_labels for x in inner_list) 
                  for inner_list in output["segmented_output"]):
            raise ValueError("All integers in segmented_output must be valid keys in id_to_label")
'''


def get_supported_modalities() -> List[str]:
    return SUPPORTED_MODALITIES


def get_supported_tasks(modality: str) -> List[str]:
    if modality == "time_series":
        return TIME_SERIES_SUPPORTED_TASKS
    else:
        raise ValueError(
            f"Modality {modality} not (yet) supported, choose from {TIME_SERIES_SUPPORTED_TASKS}")


def get_output_structure(modality: str, task_name: str) -> str:
    if modality == "time_series":
        if task_name == "classification":
            return TIME_SERIES_CLASSIFICATION_OUTPUT_STRUCTURE
        elif task_name == "forecasting":
            return TIME_SERIES_FORECASTING_OUTPUT_STRUCTURE
        elif task_name == "segmentation":
            return TIME_SERIES_SEGMENTATION_OUTPUT_STRUCTURE
    else:
        raise ValueError(f"Modality {modality} not (yet) supported")


def get_validation_code(modality: str, task_name: str) -> str:
    if modality == "time_series":
        if task_name == "classification":
            return TIME_SERIES_CLASSIFICATION_VALIDATION
        elif task_name == "forecasting":
            return TIME_SERIES_FORECASTING_VALIDATION
        elif task_name == "segmentation":
            return TIME_SERIES_SEGMENTATION_VALIDATION
        else:
            raise ValueError(
                f"Task {task_name} not (yet) supported for time series data")
    else:
        raise ValueError(f"Modality {modality} not (yet) supported")
