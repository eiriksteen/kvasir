"""update_data_integration_models_with_new_tables_and_columns

Revision ID: ee11faba8a0e
Revises: f6b43b05f4aa
Create Date: 2025-07-24 16:44:52.416151

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa


# revision identifiers, used by Alembic.
revision: str = 'ee11faba8a0e'
down_revision: Union[str, None] = 'f6b43b05f4aa'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('tabular_file_data_source',
                    sa.Column('id', sa.UUID(), nullable=False),
                    sa.Column('num_rows', sa.Integer(), nullable=False),
                    sa.Column('num_columns', sa.Integer(), nullable=False),
                    sa.Column('created_at', sa.DateTime(
                        timezone=True), nullable=False),
                    sa.Column('updated_at', sa.DateTime(
                        timezone=True), nullable=False),
                    sa.ForeignKeyConstraint(
                        ['id'], ['data_integration.file_data_source.id'], ),
                    sa.PrimaryKeyConstraint('id'),
                    schema='data_integration'
                    )
    op.create_table('feature_in_tabular_file',
                    sa.Column('feature_name', sa.String(), nullable=False),
                    sa.Column('tabular_file_id', sa.UUID(), nullable=False),
                    sa.Column('created_at', sa.DateTime(
                        timezone=True), nullable=False),
                    sa.Column('updated_at', sa.DateTime(
                        timezone=True), nullable=False),
                    sa.ForeignKeyConstraint(
                        ['feature_name'], ['data_objects.feature.name'], ),
                    sa.ForeignKeyConstraint(['tabular_file_id'], [
                        'data_integration.tabular_file_data_source.id'], ),
                    sa.PrimaryKeyConstraint('feature_name', 'tabular_file_id'),
                    schema='data_integration'
                    )
    op.add_column('data_integration_job_input', sa.Column('updated_at', sa.DateTime(
        timezone=True), nullable=False), schema='data_integration')
    op.add_column('data_integration_job_result', sa.Column('updated_at', sa.DateTime(
        timezone=True), nullable=False), schema='data_integration')
    op.add_column('data_source', sa.Column('quality_description',
                  sa.String(), nullable=True), schema='data_integration')
    op.add_column('data_source', sa.Column('content_preview',
                  sa.String(), nullable=True), schema='data_integration')
    op.add_column('data_source_group', sa.Column('updated_at', sa.DateTime(
        timezone=True), nullable=False), schema='data_integration')
    op.add_column('data_source_in_group', sa.Column('updated_at', sa.DateTime(
        timezone=True), nullable=False), schema='data_integration')
    # Delete existing rows to allow adding NOT NULL columns
    op.execute("DELETE FROM data_integration.file_data_source")
    op.add_column('file_data_source', sa.Column('file_size_bytes',
                  sa.BigInteger(), nullable=False), schema='data_integration')
    op.add_column('file_data_source', sa.Column('updated_at', sa.DateTime(
        timezone=True), nullable=False), schema='data_integration')
    op.drop_column('file_data_source', 'description',
                   schema='data_integration')
    op.drop_column('feature', 'category_id', schema='data_objects')
    op.drop_column('feature', 'source', schema='data_objects')
    op.add_column('feature_in_group', sa.Column(
        'category_id', sa.Integer(), nullable=True), schema='data_objects')

    # Update the data_source type constraint to include 'TabularFile'
    op.drop_constraint('data_source_type_check', 'data_source',
                       schema='data_integration', type_='check')
    op.create_check_constraint('data_source_type_check', 'data_source',
                               "type IN ('file', 'TabularFile')", schema='data_integration')
    # ### end Alembic commands ###


def downgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_column('feature_in_group', 'category_id', schema='data_objects')
    op.add_column('feature', sa.Column('source', sa.VARCHAR(),
                  autoincrement=False, nullable=False), schema='data_objects')
    op.add_column('feature', sa.Column('category_id', sa.INTEGER(),
                  autoincrement=False, nullable=True), schema='data_objects')
    op.add_column('file_data_source', sa.Column('description', sa.VARCHAR(
    ), autoincrement=False, nullable=True), schema='data_integration')
    op.drop_column('file_data_source', 'updated_at', schema='data_integration')
    op.drop_column('file_data_source', 'file_size_bytes',
                   schema='data_integration')
    op.drop_column('data_source_in_group', 'updated_at',
                   schema='data_integration')
    op.drop_column('data_source_group', 'updated_at',
                   schema='data_integration')
    op.drop_column('data_source', 'content_preview', schema='data_integration')
    op.drop_column('data_source', 'quality_description',
                   schema='data_integration')
    op.drop_column('data_integration_job_result',
                   'updated_at', schema='data_integration')
    op.drop_column('data_integration_job_input',
                   'updated_at', schema='data_integration')
    op.drop_table('feature_in_tabular_file', schema='data_integration')
    op.drop_table('tabular_file_data_source', schema='data_integration')

    # Restore the original data_source type constraint
    op.drop_constraint('data_source_type_check', 'data_source',
                       schema='data_integration', type_='check')
    op.create_check_constraint(
        'data_source_type_check', 'data_source', "type IN ('file')", schema='data_integration')
    # ### end Alembic commands ###
